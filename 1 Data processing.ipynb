{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "### Executive summary\n",
    "#### This script performs pre processing of the original datasets and performs statistic analysis on the pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import math\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Original Dataset import and preprocessing\n",
    "## To be executed only in case of modifications to the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\luigi\\OneDrive\\2 University\\4 ULB\\0 THESIS\\DATA\\sample_trades_intraday_DE.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\luigi\\OneDrive\\2 University\\4 ULB\\0 THESIS\\DATA\\sample_trades_intraday_DE_complete.csv',parse_dates=['timestamp','datetime'])\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['day_week'] = df['timestamp'].dt.day_name()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "df['second'] = df['timestamp'].dt.second\n",
    "df = df.set_index('timestamp')\n",
    "df.sort_values(by=['timestamp'])\n",
    "df['timestamp'] = df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Unnamed: 0':'numeric_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numeric_index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 1\n",
    "df_split = np.array_split(df, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sct.describe(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generation of a working dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep **max one datapoint per second**. Therefore, we take the average of the volume and of the price of datapoints that have the same timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the columns of our new dataframe\n",
    "volume = []\n",
    "price = []\n",
    "timestamp = []\n",
    "datetime = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    # We select only the unique timestamps\n",
    "    unique_timestamps = df[i].timestamp.unique()\n",
    "\n",
    "    #i = 0\n",
    "    # we cycle on the unique timestamps to create the new columns\n",
    "    for t in unique_timestamps:\n",
    "        #j=j+1\n",
    "        # we select all the rows that correspond to the same timestamp\n",
    "        mask = (df[i].timestamp == t)\n",
    "\n",
    "        # We average the volumes\n",
    "        volume.append(np.mean(df[i].volume[mask]))\n",
    "\n",
    "        # We average the prices\n",
    "        price.append(np.mean(df[i].price[mask]))\n",
    "        \n",
    "        # we append the timestamps\n",
    "        timestamp.append(t)\n",
    "        \n",
    "        # We append the datetime\n",
    "        if (len(df[i].numeric_index[mask])>1):\n",
    "            \n",
    "            location = np.array(df[i].numeric_index[mask])[0]\n",
    "        else:\n",
    "            location = float(df[i].numeric_index[mask])\n",
    "            \n",
    "        #starting_index = df[i].datetime.index[0]\n",
    "        #location_index = np.where(mask == False)[0][0]\n",
    "        datetime.append(df[i].datetime[location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the columns of our new dataframe\n",
    "volume = []\n",
    "price = []\n",
    "timestamp = []\n",
    "datetime = []\n",
    "\n",
    "\n",
    "# We select only the unique timestamps\n",
    "unique_timestamps = df.timestamp.unique()\n",
    "\n",
    "#i = 0\n",
    "# we cycle on the unique timestamps to create the new columns\n",
    "for t in unique_timestamps:\n",
    "#j=j+1\n",
    "# we select all the rows that correspond to the same timestamp\n",
    "    mask = (df.timestamp == t)\n",
    "\n",
    "    # We average the volumes\n",
    "    volume.append(np.mean(df.volume[mask]))\n",
    "\n",
    "    # We average the prices\n",
    "    price.append(np.mean(df.price[mask]))\n",
    "\n",
    "    # we append the timestamps\n",
    "    timestamp.append(t)\n",
    "\n",
    "    # We append the datetime\n",
    "    if (len(df.numeric_index[mask])>1):\n",
    "\n",
    "        location = np.array(df.numeric_index[mask])[0]\n",
    "    else:\n",
    "        location = float(df.numeric_index[mask])\n",
    "\n",
    "    #starting_index = df[i].datetime.index[0]\n",
    "    #location_index = np.where(mask == False)[0][0]\n",
    "    datetime.append(df.datetime[location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now create our new dataframe containing only unique values per every second\n",
    "df_new = {'datetime': datetime,\n",
    "          'volume': volume,\n",
    "          'price': price,\n",
    "          'timestamp': timestamp}\n",
    "# We want our dataframe to be sorted according to the timestamp (from the oldest to the newest datapoint)\n",
    "df_new = pd.DataFrame(df_new, index=timestamp)\n",
    "df_new = df_new.sort_values(by='timestamp')\n",
    "\n",
    "# We also want to identify  the different days and separate them from each other\n",
    "dates = df_new['timestamp'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows original dataframe: ',len(df_original.timestamp))\n",
    "print('Rows new dataframe: ',len(df_new.timestamp))\n",
    "print('Unique timestamps original dataframe: ',len(df_original.timestamp.unique()))\n",
    "print('Unique timestamps new dataframe: ',len(df_new.timestamp.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('EPEX_small_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select only the unique timestamps\n",
    "unique_timestamps = df.timestamp.unique()\n",
    "\n",
    "# We initialize the columns of our new dataframe\n",
    "volume = []\n",
    "price = []\n",
    "timestamp = []\n",
    "datetime = []\n",
    "\n",
    "# we cycle on the unique timestamps to create the new columns\n",
    "for t in unique_timestamps:\n",
    "    \n",
    "    # we select all the rows that correspond to the same timestamp\n",
    "    mask = (df.timestamp == t)\n",
    "    \n",
    "    # We average the volumes\n",
    "    volume.append(np.mean(df.volume[mask]))\n",
    "    \n",
    "    # We average the prices\n",
    "    price.append(np.mean(df.price[mask]))\n",
    "    \n",
    "    # we append the timestamps\n",
    "    timestamp.append(t)\n",
    "    starting_index = df.datetime.index[0]\n",
    "    location_index = np.where(mask == False)[0][0]\n",
    "    datetime.append(starting_index + location_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Import of pre-processed dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Import of the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Small EPEX dataset (5 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_small = pd.read_csv(r'C:\\Users\\luigi\\OneDrive\\2 University\\4 ULB\\0 THESIS\\DATA\\EPEX_small_preprocessed.csv',parse_dates=['timestamp','datetime'])\n",
    "df_new_small = df_new_small.set_index('timestamp')\n",
    "del df_new_small['Unnamed: 0']\n",
    "df_new_small['timestamp'] = df_new_small.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Including information from the dates (5 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract useful details from the timestamp and we add them to the dataframe\n",
    "df_new_small['month'] = df_new_small['timestamp'].dt.month\n",
    "df_new_small['day'] = df_new_small['timestamp'].dt.day\n",
    "df_new_small['day_week'] = df_new_small['timestamp'].dt.day_name()\n",
    "df_new_small['hour'] = df_new_small['timestamp'].dt.hour\n",
    "df_new_small['minute'] = df_new_small['timestamp'].dt.minute\n",
    "df_new_small['second'] = df_new_small['timestamp'].dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Big EPEX dataset (2 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_big = pd.read_csv(r'C:\\Users\\luigi\\OneDrive\\2 University\\4 ULB\\0 THESIS\\DATA\\EPEX_big_preprocessed.csv',parse_dates=['timestamp','datetime'])\n",
    "df_new_big = df_new_big.set_index('timestamp')\n",
    "del df_new_big['Unnamed: 0']\n",
    "df_new_big['timestamp'] = df_new_big.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Including information from the dates (2 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract useful details from the timestamp and we add them to the dataframe\n",
    "df_new_big['month'] = df_new_big['timestamp'].dt.month\n",
    "df_new_big['day'] = df_new_big['timestamp'].dt.day\n",
    "df_new_big['day_week'] = df_new_big['timestamp'].dt.day_name()\n",
    "df_new_big['hour'] = df_new_big['timestamp'].dt.hour\n",
    "df_new_big['minute'] = df_new_big['timestamp'].dt.minute\n",
    "df_new_big['second'] = df_new_big['timestamp'].dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Choice of the dataset for the resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Derived averaged datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 60s average (one minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We identify the number of missing rows\n",
    "df_new_minute = df_new.resample('min').mean()\n",
    "NAN_60s = pd.isna(df_new_minute.price)\n",
    "NAN_60s_tot = np.sum(NAN_60s)\n",
    "\n",
    "\n",
    "df_new_minute = df_new.resample('min').mean().bfill()\n",
    "df_new_minute['timestamp'] = df_new.timestamp.resample('min').bfill()\n",
    "df_new_minute['datetime'] = df_new.datetime.resample('min').bfill()\n",
    "\n",
    "print('Total number of values filled: ', NAN_60s_tot ,' Corresponding to ', NAN_60s_tot/len(df_new_minute.price)*100, '% of the total') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# Values to plot\n",
    "plt.plot(df_new_minute.price, label = 'Prices 1-minute average')\n",
    "plt.plot(df_new_minute.price[NAN_60s],color = 'r',marker='o',markersize=1,linewidth=0, label = 'samples filled')\n",
    "\n",
    "\n",
    "plt.title('1-minute average',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 30s average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_30s = df_new.resample('30S').mean()\n",
    "NAN_30s = pd.isna(df_new_30s.price)\n",
    "NAN_30s_tot = np.sum(NAN_30s)\n",
    "\n",
    "df_new_30s = df_new.resample('30S').mean().bfill()\n",
    "df_new_30s['timestamp'] = df_new.timestamp.resample('30S').bfill()\n",
    "df_new_30s['datetime'] = df_new.datetime.resample('30S').bfill()\n",
    "#df_new_30s['second'] = np.floor(df_new_30s.second/30)*30\n",
    "\n",
    "print('Total number of values filled: ', NAN_30s_tot ,' Corresponding to ', NAN_30s_tot/len(df_new_30s.price)*100, '% of the total') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df_new_30s.price, label = 'Prices 30s average')\n",
    "plt.plot(df_new_30s.price[NAN_30s],color = 'r',marker='o',markersize=1, linewidth=0, label = 'samples filled')\n",
    "\n",
    "plt.title('30s average',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 15s average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_15s = df_new.resample('15S').mean()\n",
    "NAN_15s = pd.isna(df_new_15s.price)\n",
    "NAN_15s_tot = np.sum(NAN_15s)\n",
    "\n",
    "df_new_15s = df_new.resample('15S').mean().bfill()\n",
    "df_new_15s['timestamp'] = df_new.timestamp.resample('15S').bfill()\n",
    "df_new_15s['datetime'] = df_new.datetime.resample('15S').bfill()\n",
    "#df_new_30s['second'] = np.floor(df_new_30s.second/30)*30\n",
    "\n",
    "print('Total number of values filled: ', NAN_15s_tot ,' Corresponding to ', NAN_15s_tot/len(df_new_15s.price)*100, '% of the total') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df_new_15s.price,label = 'Prices 15s average')\n",
    "plt.plot(df_new_15s.price[NAN_15s],color = 'r',marker='o',markersize=1, linewidth=0,label = 'samples filled')\n",
    "\n",
    "plt.title('15s average',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 1s expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_1s = df_new.resample('S').mean()\n",
    "NAN_1s = pd.isna(df_new_1s.price)\n",
    "NAN_1s_tot = np.sum(NAN_1s)\n",
    "\n",
    "df_new_1s = df_new.resample('S').mean().bfill()\n",
    "df_new_1s['timestamp'] = df_new.timestamp.resample('1S').bfill()\n",
    "df_new_1s['datetime'] = df_new.datetime.resample('1S').bfill()\n",
    "print('Total number of values filled: ', NAN_1s_tot ,' Corresponding to ', NAN_1s_tot/len(df_new_1s.price)*100, '% of the total') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df_new_1s.price, label = 'Prices 1s average')\n",
    "plt.plot(df_new_1s.price[NAN_1s],color = 'r',marker='o',markersize=1, linewidth=0, label = 'samples filled')\n",
    "\n",
    "plt.title('1s Expansion',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 5 minutes averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_5min = df_new.resample('5min').mean()\n",
    "NAN_5min = pd.isna(df_new_5min.price)\n",
    "NAN_5min_tot = np.sum(NAN_5min)\n",
    "\n",
    "df_new_5min = df_new.resample('5min').mean().bfill()\n",
    "df_new_5min['timestamp'] = df_new.timestamp.resample('5min').bfill()\n",
    "df_new_5min['datetime'] = df_new.datetime.resample('5min').bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.6 10 minutes average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_10min = df_new.resample('10min').mean()\n",
    "NAN_10min = pd.isna(df_new_10min.price)\n",
    "NAN_10min_tot = np.sum(NAN_10min)\n",
    "\n",
    "df_new_10min = df_new.resample('10min').mean().bfill()\n",
    "df_new_10min['timestamp'] = df_new.timestamp.resample('10min').bfill()\n",
    "df_new_10min['datetime'] = df_new.datetime.resample('10min').bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_10min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.7 15 minutes average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_15min = df_new.resample('15min').mean()\n",
    "NAN_15min = pd.isna(df_new_15min.price)\n",
    "NAN_15min_tot = np.sum(NAN_15min)\n",
    "\n",
    "df_new_15min = df_new.resample('15min').mean().bfill()\n",
    "df_new_15min['timestamp'] = df_new.timestamp.resample('15min').bfill()\n",
    "df_new_15min['datetime'] = df_new.datetime.resample('15min').bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.8 30 minutes average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_30min = df_new.resample('30min').mean()\n",
    "NAN_30min = pd.isna(df_new_30min.price)\n",
    "NAN_30min_tot = np.sum(NAN_30min)\n",
    "\n",
    "df_new_30min = df_new.resample('30min').mean().bfill()\n",
    "df_new_30min['timestamp'] = df_new.timestamp.resample('30min').bfill()\n",
    "df_new_30min['datetime'] = df_new.datetime.resample('30min').bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the pre-processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_big.to_csv('DF_big_processed.csv')\n",
    "df_new_30s.to_csv('df_30s_processed.csv')\n",
    "df_new_15s.to_csv('df_15s_processed.csv')\n",
    "df_new_minute.to_csv('df_minute_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_5min.to_csv('df_5min_processed.csv')\n",
    "df_new_10min.to_csv('df_10min_processed.csv')\n",
    "df_new_15min.to_csv('df_15min_processed.csv')\n",
    "df_new_30min.to_csv('df_30min_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 10-minute average (to be fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of all the timestamps\n",
    "stamps = df_new.timestamp\n",
    "\n",
    "# We create an empty list for the averaged volume prices\n",
    "weighted_volume_prices_averaged = []\n",
    "for time in stamps: \n",
    "    central_time = time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of all the timestamps\n",
    "stamps = df_new.timestamp\n",
    "\n",
    "# We create an empty list for the averaged volume prices\n",
    "weighted_volume_prices_averaged = []\n",
    "\n",
    "# We iterate on every datapoint calculating the 10-minutes averages of the price weighted on the volume\n",
    "for time in stamps: \n",
    "    central_time = time\n",
    "    \n",
    "    # The datapoint 5 minutes ahead the current point\n",
    "    five_min_up = pd.Timestamp(central_time) + dt.timedelta(minutes = 5)\n",
    "    \n",
    "    # The datapoint 5 minutes behing the current data point\n",
    "    five_min_down = pd.Timestamp(central_time) - dt.timedelta(minutes = 5)\n",
    "    \n",
    "    # The volume weighted average of the electricity price (10-minute based)\n",
    "    weighted_volume_prices_averaged.append(np.average(df_new.price[five_min_down:five_min_up], \n",
    "                                                      weights=df_new.volume[five_min_down:five_min_up]))\n",
    "\n",
    "# we add the volume weighted average to the dataframe\n",
    "df_new['weighted_volume_prices_averaged'] = weighted_volume_prices_averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See resample reference: https://towardsdatascience.com/resample-function-of-pandas-79b17ec82a78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Overlapped daily graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df_new['timestamp'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can plot the days overlapped to each other\n",
    "plt.subplots(figsize=(20, 10))\n",
    "for date in dates:\n",
    "\n",
    "    mask = df_new['timestamp'].dt.date == date\n",
    "    x = df_new.timestamp.dt.time[mask]\n",
    "    plt.plot(x,df_new.price[mask], label = date)\n",
    "\n",
    "plt.title('Full dataset of intraday prices - overlapped',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "#plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.4 Days in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "for date in dates:\n",
    "\n",
    "    mask = df_new['timestamp'].dt.date == date\n",
    "    plt.plot(df_new.price[mask], label = date)\n",
    "    \n",
    "#plt.plot(df_new.weighted_volume_prices_averaged, label = '10 minutes prices average weighted on the volume')\n",
    "#plt.plot(df_new_minute.price, 'r', label = 'minute average',)\n",
    "plt.title('Full dataset of intraday prices',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "#plt.ylim(-200,250)\n",
    "plt.grid()    \n",
    "#plt.legend(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_big = df_new_big['timestamp'].dt.date.unique()\n",
    "plt.subplots(figsize=(20, 10))\n",
    "for date in dates_big:\n",
    "\n",
    "    mask = df_new_big['timestamp'].dt.date == date\n",
    "    plt.plot(df_new_big.price[mask], label = date)\n",
    "    \n",
    "#plt.plot(df_new.weighted_volume_prices_averaged, label = '10 minutes prices average weighted on the volume')\n",
    "#plt.plot(df_new_minute.price, 'r', label = 'minute average',)\n",
    "plt.title('Full dataset of intraday prices',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white',rotation=45, ha=\"right\")\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.ylim(-200,250)\n",
    "plt.grid()    \n",
    "#plt.legend(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Estimation of the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialization of the model, a linear regression with intercept\n",
    "model = LinearRegression(fit_intercept = True, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generations of the arrays for the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([range(0,len(df_new.price))]).T\n",
    "\n",
    "# Prices are converted into int for memory allocation reasons\n",
    "y = df_new.price.astype(int)\n",
    "\n",
    "# Fitting of the model and estimation of the predictions\n",
    "model.fit(x1, y)\n",
    "prediction = model.predict(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot of the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(df.price, label = 'Intraday prices')\n",
    "plt.plot(df.index, prediction, color='r', label = 'Linear regression trend', linewidth=5)\n",
    "\n",
    "slope = round(model.coef_[0],7)\n",
    "plt.title('Trend of the dataset, estimated with linear regression. Slope = %s ' % slope,fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white',rotation=45, ha=\"right\")\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Display of the high volatility of the dataset (to be fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose a certain timeframe to show in the plot for each of the datasets that we want to plot\n",
    "\n",
    "mask = (df_new_small.month == 6) &(df_new_small.day == 2) & (df_new_small.hour == 15)\n",
    "mask_30s = (df_new_small.month == 6) & (df_new_30s.day == 2) & (df_new_30s.hour == 15)\n",
    "mask_15s = (df_new_small.month == 6) & (df_new_15s.day == 2) & (df_new_15s.hour == 15)\n",
    "mask_minute = (df_new_small.month == 6) & (df_new_minute.day == 2) & (df_new_minute.hour == 15)\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "# We plot the original dataset and the averages\n",
    "plt.plot(df_new_small.price[mask],'y', label='Original dataset')\n",
    "plt.plot(df_new_30s.price[mask_30s],'r',label='30s average')\n",
    "plt.plot(df_new_15s.price[mask_15s],'b',label='15s average')\n",
    "plt.plot(df_new_minute.price[mask_minute],'g',label='Minute average')\n",
    "\n",
    "# Items of the plot\n",
    "plt.title('Variance of the dataset',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 10 minutes time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_short = (df_new_big.month == 6) &(df_new_big.day == 2) & (df_new_big.hour == 15) & (df_new_big.minute < 10)\n",
    "mask_30s_short = (df_new_big.month == 6) & (df_new_30s.day == 2) & (df_new_30s.hour == 15) & (df_new_big.minute < 10)\n",
    "mask_15s_short = (df_new_big.month == 6) & (df_new_15s.day == 2) & (df_new_15s.hour == 15) & (df_new_big.minute < 10)\n",
    "mask_minute_short = (df_new_big.month == 6) & (df_new_minute.day == 2) & (df_new_minute.hour == 15) & (df_new_big.minute < 10)\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "# We plot the original dataset and the averages\n",
    "plt.plot(df_new_big.price[mask_short],'y', label='Original dataset')\n",
    "plt.plot(df_new_30s.price[mask_30s_short],'r',label='30s average')\n",
    "plt.plot(df_new_15s.price[mask_15s_short],'b',label='15s average')\n",
    "plt.plot(df_new_minute.price[mask_minute_short],'g',label='Minute average')\n",
    "\n",
    "# Items of the plot\n",
    "plt.title('Variance of the dataset',fontsize=30,backgroundcolor= 'white')\n",
    "plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('time',fontsize=25,backgroundcolor= 'white')\n",
    "plt.grid()    \n",
    "plt.legend(fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.4.6 experiments trying to fill the dataset with NA or with forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = df_new1.interpolate(method='ffill', limit_direction='forward')\n",
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.plot(df_new.price[mask],'b', label = 'original dataset')\n",
    "#plt.plot(df_new_minute.price[mask1],'r', label = 'minute average')\n",
    "#plt.plot(df_new1.price[mask2],'g', label = 'dataset with every second, filled NA')\n",
    "plt.plot(df_new2.price[mask2], 'y', label = 'dataset with every second, filled ffa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.plot(df_new.price[mask_short],'b', label = 'original dataset')\n",
    "plt.plot(df_new_minute.price[mask1_short],'r', label = 'minute average')\n",
    "#plt.plot(df_new1.price[mask2],'g', label = 'dataset with every second, filled NA')\n",
    "plt.plot(df_new2.price[mask2_short], 'y', label = 'dataset with every second, filled ffa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_stats = sct.describe(df.price)\n",
    "print(basic_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Histogram of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of bins: rule of **Freedman–Diaconis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sct.iqr(df_new_big.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df.price)-np.min(df.price))/h))\n",
    "n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "# We plot the original dataset and the averages\n",
    "plt.hist(df.price, bins = n_bins, label='Intraday prices')\n",
    "plt.axvline(x=basic_stats.mean,c='r', label='mean')\n",
    "#plt.ylim(0,10)\n",
    "\n",
    "# Items of the plot\n",
    "plt.xlim(-400+basic_stats.mean,400++basic_stats.mean)\n",
    "plt.title('Histogram of the dataset',fontsize=30,backgroundcolor= 'white')\n",
    "#plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "#plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('Frequency',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('Intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "#plt.grid()    \n",
    "plt.legend(fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Histogram of the Zoomed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "# We plot the original dataset and the averages\n",
    "plt.hist(df.price, bins = n_bins, label='Intraday prices')\n",
    "plt.axvline(x=basic_stats.mean,c='r', label='mean')\n",
    "plt.ylim(0,10)\n",
    "# Items of the plot\n",
    "plt.title('Histogram of the dataset - extreme values and outliers',fontsize=30,backgroundcolor= 'white')\n",
    "#plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "#plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('Frequency',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('Intraday price [€]',fontsize=25,backgroundcolor= 'white')\n",
    "#plt.grid()    \n",
    "plt.legend(fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analysis of the days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayname'] = df.timestamp.dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Calculation of the stats for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayweek_stats = []\n",
    "for dayweek in (df.dayname.unique()):\n",
    "    print(dayweek)\n",
    "    dayweek_mask = (df.dayname == dayweek)\n",
    "    dayweek_stats.append(sct.describe(df.price[dayweek_mask]))\n",
    "    print(sct.describe(df.price[dayweek_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 plot of the histograms with the mean for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Monday\n",
    "dayweek_mask = (df.dayname == 'Monday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='r',label = 'Monday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='r')\n",
    "\n",
    "\n",
    "# Tuesday\n",
    "dayweek_mask = (df.dayname == 'Tuesday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='darkorange',label = 'Tuesday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='darkorange')\n",
    "\n",
    "\n",
    "# Wednesday\n",
    "dayweek_mask = (df.dayname == 'Wednesday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='gold',label = 'Wednesday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='gold')\n",
    "\n",
    "# Thursday\n",
    "dayweek_mask = (df.dayname == 'Thursday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='lawngreen',label = 'Thursday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='lawngreen')\n",
    "\n",
    "# Friday\n",
    "dayweek_mask = (df.dayname == 'Friday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='cyan', label = 'Friday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='cyan')\n",
    "\n",
    "# Saturday\n",
    "dayweek_mask = (df.dayname == 'Saturday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.5, color='midnightblue',label = 'Saturday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='midnightblue')\n",
    "\n",
    "# Sunday\n",
    "dayweek_mask = (df.dayname == 'Sunday')\n",
    "df_week = df[dayweek_mask]\n",
    "\n",
    "N = len(df_week.price)\n",
    "h = sct.iqr(df_week.price) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(df_week.price)-np.min(df_week.price))/h))\n",
    "plt.hist(df_week.price, bins = n_bins,alpha=0.2, color='magenta', label = 'Sunday')\n",
    "plt.axvline(x=np.mean(df_week.price),c='magenta')\n",
    "\n",
    "# Items of the plot\n",
    "plt.xlim(-200,200)\n",
    "\n",
    "plt.title('Histogram of the dataset - days of the week',fontsize=30,backgroundcolor= 'white')\n",
    "#plt.xticks(fontsize=20,backgroundcolor= 'white')\n",
    "#plt.yticks(fontsize=20,backgroundcolor= 'white')\n",
    "plt.ylabel('Frequency',fontsize=25,backgroundcolor= 'white')\n",
    "plt.xlabel('Intraday price [€/MWh]',fontsize=25,backgroundcolor= 'white')\n",
    "plt.legend(fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = df.month.unique()\n",
    "days = df.day.unique()\n",
    "\n",
    "daily_stats = []\n",
    "day_stats = []\n",
    "month_stats = []\n",
    "minprice = []\n",
    "maxprice = []\n",
    "for month in months:\n",
    "    \n",
    "    for day in days:\n",
    "        mask_day = (df.month == month) & (df.day == day)\n",
    "        if len(df.price[mask_day]) == 0:\n",
    "            continue\n",
    "        stats = sct.describe(df.price[mask_day])\n",
    "        daily_stats.append(stats)\n",
    "        day_stats.append(day)\n",
    "        month_stats.append(month)\n",
    "        minprice.append(np.min(df.price[mask_day]))\n",
    "        maxprice.append(np.max(df.price[mask_day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_differences = np.array(maxprice)-np.array(minprice)\n",
    "\n",
    "N = len(min_max_differences)\n",
    "h = sct.iqr(min_max_differences) * 2 * N**(-1/3)\n",
    "n_bins = int(np.floor((np.max(min_max_differences)-np.min(min_max_differences))/h))\n",
    "\n",
    "plt.hist(min_max_differences, bins = 30, alpha=0.5, color='magenta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
